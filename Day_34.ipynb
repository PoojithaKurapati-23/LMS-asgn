{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq0rhS30IouqVt0rGGGjZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PoojithaKurapati-23/LMS-asgn/blob/main/Day_34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "grjmH9wCzFH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5eb450-2b74-444c-b3d7-c9ded900f656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Representation:\n",
            "   amazing  deep  fun  is  learning  love  machine\n",
            "0        0     0    0   0         1     1        1\n",
            "1        0     0    1   1         1     0        1\n",
            "2        1     1    0   1         1     0        0\n",
            "\n",
            "TF-IDF Representation:\n",
            "    amazing      deep       fun        is  learning      love   machine\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.425441  0.720333  0.547832\n",
            "1  0.000000  0.000000  0.631745  0.480458  0.373119  0.000000  0.480458\n",
            "2  0.584483  0.584483  0.000000  0.444514  0.345205  0.000000  0.000000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "def bag_of_words_and_tfidf(texts):\n",
        "    # Bag of Words Representation\n",
        "    count_vectorizer = CountVectorizer()\n",
        "    bow_matrix = count_vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Convert BoW to DataFrame\n",
        "    bow_df = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
        "\n",
        "    # TF-IDF Representation\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Convert TF-IDF to DataFrame\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "    return bow_df, tfidf_df\n",
        "\n",
        "# Example usage\n",
        "texts = [\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning is fun\",\n",
        "    \"Deep learning is amazing\"\n",
        "]\n",
        "\n",
        "bow, tfidf = bag_of_words_and_tfidf(texts)\n",
        "\n",
        "print(\"Bag of Words Representation:\")\n",
        "print(bow)\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(tfidf)\n"
      ]
    }
  ]
}